---
title: 26. 大文件切片上传
order: 26
comment: false
collapsible: false
date: 2024-05-5
categories: 
  - programme
  - WebFrontEnd
tags: 
  - 
columns: 
  - 

---


```javascript
<template>
  <div class="home">
    <div class="file">
      <button @click="openFileSelect">选择文件</button>
      <div @click="upload">上传</div>
      <input type="file" ref="inputFileRef" @change="inputFileChange" />
    </div>
  </div>
</template>

<script setup>
import { onMounted, reactive, ref } from "vue";
import SparkMD5 from "spark-md5";
// 获取上传实例
const inputFileRef = ref(null);
// 打开选择器
const openFileSelect = () => {
  if (inputFileRef.value) {
    inputFileRef.value.click();
  }
};
// 上传的文件，支持多文件上传
const inputFileList = reactive([]);
// 选择文件中
const inputFileChange = (e) => {
  // 选中文件
  const files = e.target.files;

  // 如果没有选择文件不做任何操作
  if (!files) return;

  // 多个文件上传
  for (let i = 0; i < files?.length; i++) {
    inputFileList.push(files[i]);
  }
};

// 确认上传
const upload = async () => {
  // 判断是否有待上传的文件
  if (inputFileList.length === 0) {
    alert("请选择文件");
    return;
  }
  // 遍历文件数组
  for (let i = 0; i < inputFileList.length; i++) {
    // 每个切片的固定大小
    let maxSize = 1024 * 1024 * 1;
    const { HASH, suffix } = await changeBuffer(inputFileList[i]);
    // 需要分片总数量
    let count = Math.ceil(inputFileList[i].size / maxSize);
    // 当切片数量大于最大限制时候，采用固定数量，防止请求过多
    if (count > 100) {
      count = 100;
      maxSize = inputFileList[i].size / count;
    }
    // 开始切片操作
    let index = 0;
    //用来存储当前文件的切片
    let chunks = [];
    while (index < count) {
      const sliceFile = inputFileList[i].slice(
        index * maxSize,
        (index + 1) * maxSize
      );
      chunks.push({
        file: sliceFile,
        name: `${HASH}_${index}.${suffix}`,
      });
      index++;
    }
      console.log("chunks",chunks);
    // 在此处进行请求，获取该文件是否有已上传切片
    const uploadedFileList = await axios.get("/file");

    // 筛选出未上传的切片
    if (uploadedFileList.length) {
      chunks = chunks.filter((chunk) => !uploadedFileList.includes(chunk));
    }

    // 用于判断是否上传完成
    let uplopedCount = 0;
    const uploped = () => {
      uplopedCount++;
      // 当所有切片都上传完成,像后端发送请求合并操作
      if (uplopedCount > count) {
        const result = axois.post("/merge", {
          hash: HASH,
        });
      }
    };

    // 进行切片上传
    for (let i = 0; i < chunks.length; i++) {
      const fm = new formData();
      fm.append("file", chunks[i].file);
      fm.append("name", chunks[i].name);
      axios.post("/file", fm).then((result) => {
        // 如果当前切片上传成功，进入uploped函数，用于判断该文件切片是否全部上传完成。
        if (result.code === 200) uploped();
      });
    }
  }

};

// md5
const changeBuffer = (file) => {
  return new Promise((resolve, reject) => { 
    // 要通过 spark-md5 得到 hash 需要先获取文件的buffer值
    // 异步读取存储在用户计算机上的文件（或原始数据缓冲区）的内容，使用 File 或 Blob 对象指定要读取的文件或数据。
    const fileReader =` `

    // 开始读取指定的 Blob中的内容，一旦完成，result 属性中保存的将是被读取文件的 ArrayBuffer 数据对象。
    fileReader.readAsArrayBuffer(file);
    // 处理load事件。该事件在读取操作完成时触发。
    fileReader.onload = (e) => {
      const BUFFER = e.target?.result;
      if (!BUFFER) reject();
      const HASH = new SparkMD5.ArrayBuffer().append(BUFFER).end();
      // 获取文件后缀，后续单独拼接切片文件名
      const suffix = /\.([a-zA-Z0-9]+)$/.exec(file.name)[1];
      console.log(HASH,suffix);
      resolve({
        HASH,
        suffix,
      });
    };
  });
};
onMounted(() => {});
</script>
<style scoped lang='less'>
.home {
  width: 100%;
  height: 100%;
  display: flex;
  justify-content: center;
  // .file {
  //   display: flex;
  // }
}
</style>

```
